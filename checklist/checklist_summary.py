# checklist/checklist_summary.py
from typing import List, Dict
from langchain_openai import ChatOpenAI
from pydantic import BaseModel
import os
import json
import re
from openai import OpenAI


class ChecklistSummaryRequest(BaseModel):
    templateId: int
    comments: List[str]

class ChecklistSummaryResponse(BaseModel):
    positive: List[str]
    negative: List[str]
    suggestions: List[str]
    
# =========================
# PRE ìœ„í—˜ ì„¤ëª… (ì‚¬ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸)
# =========================

class PreRiskExplanationRequest(BaseModel):
    riskScoreSum: float
    reasons: List[str]


class PreRiskExplanationResponse(BaseModel):
    summary: str
    actions: List[str]

    
def is_meaningful_comment(comment: str) -> bool:
    """
    ì˜ë¯¸ ì—†ëŠ” / í…ŒìŠ¤íŠ¸ìš© / ìš´ì˜ ë©”íƒ€ ì½”ë©˜íŠ¸ í•„í„°ë§
    """
    c = comment.strip()

    # 1ï¸âƒ£ ê¸¸ì´ ê¸°ë°˜
    if len(c) < 5:
        return False

    # 2ï¸âƒ£ ë°˜ë³µ ë¬¸ì
    if re.fullmatch(r"(.)\1{3,}", c):
        return False

    # 3ï¸âƒ£ ìëª¨ë§Œ ìˆëŠ” ê²½ìš°
    if re.fullmatch(r"[ã„±-ã…ã…-ã…£]+", c):
        return False

    # 4ï¸âƒ£ ì™„ì „ ë¬´ì˜ë¯¸ ë‹¨ì–´
    meaningless_exact = {
        "test", "asdf", "qwer", "...", "???", "!!!"
    }
    if c.lower() in meaningless_exact:
        return False

    # 5ï¸âƒ£ ğŸ”¥ ê°œë°œ/ìš´ì˜/í…ŒìŠ¤íŠ¸ ë©”íƒ€ ì½”ë©˜íŠ¸ ì°¨ë‹¨
    meaningless_keywords = [
        "í…ŒìŠ¤íŠ¸", "test", "í…ŒìŠ¤íŠ¸ì¤‘", "í™•ì¸",
        "ê°œë°œ", "ê°œë°œì¤‘", "ë””ë²„ê·¸",
        "ai", "ë¶„ê¸°", "ë¡œì§", "api",
        "ìš”ì•½", "ì™„ì„±", "í™•ì¸ìš©",
        "ì§‘ì—ì„œ", "íšŒì‚¬ì—ì„œ"
    ]

    lowered = c.lower()
    if any(k in lowered for k in meaningless_keywords):
        return False

    return True

def is_summary_worthy_comment(comment: str) -> bool:
    """
    ì´ ì½”ë©˜íŠ¸ê°€ 'ì‚¬ìš©ì ê²½í—˜/ê°œì„  ìš”ì•½'ì—
    ì‹¤ì§ˆì ìœ¼ë¡œ ê°€ì¹˜ê°€ ìˆëŠ”ì§€ LLMìœ¼ë¡œ íŒë³„
    """

    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    prompt = f"""
ë‹¤ìŒ ì‚¬ìš©ì ì½”ë©˜íŠ¸ê°€
ì²´í¬ë¦¬ìŠ¤íŠ¸ ì‚¬ìš© ê²½í—˜, ë§Œì¡±/ë¶ˆë§Œ, ê°œì„ ì  íŒŒì•…ì—
ì˜ë¯¸ ìˆëŠ” ì •ë³´ì¸ì§€ íŒë‹¨í•˜ë¼.

ë‹¤ìŒ ìœ í˜•ì€ false:
- í…ŒìŠ¤íŠ¸/ê°œë°œ/í™•ì¸ ëª©ì 
- ì˜ë¯¸ ì—†ëŠ” ê°ìƒ
- êµ¬ì²´ì  ê²½í—˜ì´ ì—†ëŠ” ì§§ì€ í‰ê°€

ë°˜ë“œì‹œ true ë˜ëŠ” false ì¤‘ í•˜ë‚˜ë§Œ ì¶œë ¥í•˜ë¼.

ì½”ë©˜íŠ¸:
{comment}
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì œí’ˆ UX ë¶„ì„ ì „ë¬¸ê°€ë‹¤."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.0,
        )

        result = response.choices[0].message.content.strip().lower()
        return result == "true"

    except Exception:
        # ğŸ”’ ì‹¤íŒ¨ ì‹œ ë³´ìˆ˜ì ìœ¼ë¡œ ì œì™¸
        return False


def call_llm_for_summary(comments: List[str]) -> dict:
    """
    ë§Œì¡±ë„ ì½”ë©˜íŠ¸ ìš”ì•½
    """
    
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    prompt = f"""
ë‹¤ìŒì€ ì²´í¬ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©ì ë§Œì¡±ë„ ì½”ë©˜íŠ¸ ëª©ë¡ì´ë‹¤.

ë°˜ë“œì‹œ JSONìœ¼ë¡œë§Œ ì‘ë‹µí•˜ë¼.
ì„¤ëª…, ë§ˆí¬ë‹¤ìš´, ì½”ë“œë¸”ë¡ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆë¼.

í˜•ì‹:
{{
  "positive": ["..."],
  "negative": ["..."],
  "suggestions": ["..."]
}}

ì½”ë©˜íŠ¸:
{chr(10).join(comments)}
"""

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ì²´í¬ë¦¬ìŠ¤íŠ¸ UX ë¶„ì„ ì „ë¬¸ê°€ë‹¤."},
            {"role": "user", "content": prompt},
        ],
        temperature=0.4,
    )

    try:
        result = json.loads(response.choices[0].message.content.strip())
        if not result.get("suggestions"):
            result["suggestions"] = ["íŠ¹ì´ ì œì•ˆ ì—†ìŒ."]
        return result
    except Exception:
        return {
            "positive": [],
            "negative": [],
            "suggestions": ["ìš”ì•½ ìƒì„± ì‹¤íŒ¨"]
        }
    


class ChecklistSummaryService:
    """
    ì‚¬ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ì „ìš© ì„œë¹„ìŠ¤
    - RAG/Scoringì—ì„œ ì„ ë³„ëœ ìƒìœ„ reasonì„
      ì‚¬ìš©ììš© ìš”ì•½ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜
    """

    def __init__(self):
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.3,
            openai_api_key=os.getenv("OPENAI_API_KEY")
        )

    def summarize_pre_result(
        self,
        top_reasons: List[str],
        max_lines: int = 3
    ) -> Dict:
        """
        ì‚¬ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìš”ì•½ ìƒì„±
        - ì´ë¯¸ ì¤‘ìš”ë„ë¡œ ì„ ë³„ëœ reasonë§Œ ì‚¬ìš©
        """

        if not top_reasons:
            return {
                "summary": "ì‚¬ì „ ì ê²€ ê²°ê³¼, íŠ¹ë³„íˆ ì£¼ì˜ê°€ í•„ìš”í•œ í•­ëª©ì€ í™•ì¸ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "actions": ["ê³„ì•½ ì „ ê¸°ë³¸ ì‚¬í•­ì„ í•œ ë²ˆ ë” ì ê²€í•´ ì£¼ì„¸ìš”."]
            }

        prompt = f"""
ë„ˆëŠ” ì „ì„¸ ê³„ì•½ì„ ì•ë‘” ì‚¬ìš©ìë¥¼ ë•ëŠ”
ì‚¬ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸ ì•ˆë‚´ AIë‹¤.

ëª©í‘œ:
- ì‚¬ìš©ìê°€ í˜„ì¬ ìƒíƒœë¥¼ ì°¨ë¶„íˆ ì´í•´í•˜ë„ë¡ ë•ëŠ”ë‹¤
- ìœ„í—˜ì„ ê³¼ì¥í•˜ì§€ ì•ŠëŠ”ë‹¤
- ê³„ì•½ íŒë‹¨ì´ë‚˜ ê²°ë¡ ì€ ì ˆëŒ€ ì œì‹œí•˜ì§€ ì•ŠëŠ”ë‹¤

ì‘ì„± ê·œì¹™:
- ìµœëŒ€ {max_lines}ë¬¸ì¥
- ê³µí¬Â·ë‹¨ì •Â·ë²•ì  í‘œí˜„ ê¸ˆì§€
- ì•ˆë‚´í˜•, ì„¤ëª…í˜• ì–´ì¡°
- ë°˜ë“œì‹œ ì•„ë˜ ì œê³µëœ ë‚´ìš©ë§Œ ê·¼ê±°ë¡œ ì‚¬ìš©
- JSON ì™¸ í…ìŠ¤íŠ¸ ì¶œë ¥ ê¸ˆì§€

[ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•œ ì‚¬ìœ ]
{chr(10).join(top_reasons)}

ì¶œë ¥ í˜•ì‹:
{{
  "summary": "ìš”ì•½ ë¬¸ì¥",
  "actions": [
    "ê¶Œì¥ í–‰ë™ 1",
    "ê¶Œì¥ í–‰ë™ 2"
  ]
}}
"""

        response = self.llm.invoke(prompt).content.strip()

        try:
            return json.loads(response)
        except Exception:
            # LLM ì‹¤íŒ¨ ì‹œ ë³´ìˆ˜ì  fallback
            return {
                "summary": "ì‚¬ì „ ì ê²€ ê²°ê³¼, ì¼ë¶€ í•­ëª©ì— ëŒ€í•´ ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                "actions": [
                    "ê³„ì•½ ì „ ê´€ë ¨ í•­ëª©ì„ ë‹¤ì‹œ í•œ ë²ˆ ì ê²€í•´ ë³´ì„¸ìš”.",
                    "í•„ìš”í•˜ë‹¤ë©´ ì „ë¬¸ê°€ì˜ ë„ì›€ì„ ë°›ì•„ í™•ì¸í•´ ë³´ì„¸ìš”."
                ]
            }
        
    def summarize_safe_pre_result(self) -> Dict:
        """
        ì‚¬ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸ 'ë¬¸ì œ ì—†ìŒ' ìƒíƒœ ìš”ì•½
        (POST_A + ë¯¸ì´í–‰ 0ê°œ ì „ìš©)
        """

        prompt = """
ë„ˆëŠ” ì „ì„¸ ê³„ì•½ ì‚¬ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼
ëª¨ë‘ ì™„ë£Œí•œ ì‚¬ìš©ìë¥¼ ìœ„í•œ ì•ˆë‚´ ìš”ì•½ AIë‹¤.

ëª©í‘œ:
- ì‚¬ìš©ìê°€ í˜„ì¬ ìƒíƒœë¥¼ ê¸ì •ì ìœ¼ë¡œ ì¸ì‹í•˜ë„ë¡ ë•ëŠ”ë‹¤
- ë°©ì‹¬í•˜ì§€ ì•Šë„ë¡ ë¶€ë“œëŸ¬ìš´ ì£¼ì˜ë¥¼ í•¨ê»˜ ì „ë‹¬í•œë‹¤
- ê³„ì•½ íŒë‹¨ì´ë‚˜ ê²°ë¡ ì€ ì œì‹œí•˜ì§€ ì•ŠëŠ”ë‹¤

ì‘ì„± ê·œì¹™:
- ìµœëŒ€ 2ë¬¸ì¥
- ê³¼ì¥Â·ë‹¨ì •Â·ê³µí¬ í‘œí˜„ ê¸ˆì§€
- ì•ˆì‹¬ + ì ê²€ ìœ ë„ í†¤
- JSON ì™¸ í…ìŠ¤íŠ¸ ì¶œë ¥ ê¸ˆì§€

ì¶œë ¥ í˜•ì‹:
{
  "summary": "ìš”ì•½ ë¬¸ì¥",
  "actions": [
    "ê¶Œì¥ í–‰ë™ 1"
  ]
}
"""

        response = self.llm.invoke(prompt).content.strip()

        try:
            return json.loads(response)
        except Exception:
            return {
                "summary": "ì‚¬ì „ ì ê²€ í•­ëª©ì´ ëª¨ë‘ í™•ì¸ë˜ì–´, ì „ë°˜ì ìœ¼ë¡œ ì•ˆì •ì ì¸ ìƒíƒœë¡œ ë³´ì…ë‹ˆë‹¤.",
                "actions": ["ê³„ì•½ ì „ ì„œë¥˜ë¥¼ í•œ ë²ˆ ë” ì ê²€í•´ ë³´ì„¸ìš”."]
            }
   

# ==================================================
# API ì „ìš© ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
# ==================================================
summary_service = ChecklistSummaryService()


def summarize(req: ChecklistSummaryRequest) -> ChecklistSummaryResponse:
    """
    /checklist/summary ì „ìš© ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
    """

    # 1ï¸âƒ£ ê·œì¹™ ê¸°ë°˜ í•„í„°
    rule_filtered = [
        c for c in req.comments
        if is_meaningful_comment(c)
    ]

    # 2ï¸âƒ£ LLM ê¸°ë°˜ ìš”ì•½ ê°€ì¹˜ íŒë³„
    llm_filtered = [
        c for c in rule_filtered
        if is_summary_worthy_comment(c)
    ]

    if not llm_filtered:
        return ChecklistSummaryResponse(
            positive=[],
            negative=[],
            suggestions=["ìš”ì•½í•  ë§Œí•œ ì‚¬ìš©ì ê²½í—˜ ì½”ë©˜íŠ¸ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."]
        )

    result = call_llm_for_summary(llm_filtered)

    return ChecklistSummaryResponse(
        positive=result.get("positive", []),
        negative=result.get("negative", []),
        suggestions=result.get("suggestions", []),
    )

def explain_pre_risk(req: PreRiskExplanationRequest) -> PreRiskExplanationResponse:
    """
    /checklist/pre/risk/explanation ì „ìš© ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
    """

    # ğŸ”´ ìœ„í—˜ ìš”ì•½ vs ğŸŸ¢ ì•ˆì „ ìš”ì•½ ë¶„ê¸°
    if (
        len(req.reasons) == 1
        and "ëª¨ë“  ì‚¬ì „ ì²´í¬ í•­ëª©ì´ ì™„ë£Œ" in req.reasons[0]
    ):
        result = summary_service.summarize_safe_pre_result()
    else:
        result = summary_service.summarize_pre_result(
            top_reasons=req.reasons,
            max_lines=3
        )

    return PreRiskExplanationResponse(
        summary=result["summary"],
        actions=result["actions"]
    )

